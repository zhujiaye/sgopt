\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\rhead{基于线段树优化的动态PPI网络匹配}
\chapter{基于线段树优化的动态PPI网络匹配}
%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\section{动态PPI网络及动态PPI网络匹配}
由于本文要研究的问题是如何在动态PPI网络上作网络匹配，因此要先对动态PPI网络以及动态PPI网络匹配问题重新做出定义。

%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\subsection{动态PPI网络定义}
一个动态PPI网络定义为四元组$G=(V,E,L,R)$，其中$V$是点集，$E$是边集，对于边集中的每一条边表示为$(u,v)$，其中$u$和$v$是在某一时刻具有相互作用的蛋白质点对。$L(u,v)$为边$(u,v)$处于活跃状态的开始时刻，$R(u,v)$为边$(u,v)$处于活跃状态的结束时刻，定义

\begin{equation}\label{myworkactivedefine}
Act_i(u,v)=\begin{cases}
1 & \text{  } L(u,v)\leq i\leq R(u,v), (u,v)\in E_2\\ 
0 & \text{  其他}  
\end{cases}
\end{equation}

用来表示边$(u,v)$在$i$时刻是否处于活跃状态。定义$Act_i(E)=\{(u,v):(u,v)\in E,Act_i(u,v)=1\}$表示$i$时刻下边集E中活跃的边组成的集合。

直观上看，一个动态PPI网络，就是在对应的静态PPI网络的基础上，加入了时间的元素，即每一条边$(u,v)$只会存在与某个连续的时间段$[L(u,v),R(u,v)]$内，而不是一直处于活跃状态。值得注意的是，在\cite{zhang2016method}中，动态PPI网络的定义与本文的定义稍有不同，本文为了简化问题，将边的活跃从原来的概率模型，转化成了0-1模型(即某一时刻，边$(u,v)$要么活跃，要么不活跃)，并且假设每条边的活跃范围是一个连续的时间区间。对于多个时间区间的动态PPI网络定义也是可以的，本文的算法在这种情况下也是可以扩展的，简单起见，本文定义的时间区间个数限制在1个。

%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\subsection{动态PPI网络构造}
本文主要用了\cite{zhang2016method}中的三-西格玛阈值方法，对静态PPI网络进行了动态化的转化，并且假设当边处于活跃状态的概率大于$0.5$时，边就是处于活跃状态的，否则就是不活跃状态。详细的动态PPI网络构造方法可以参见相关工作。

%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\subsection{动态PPI网络匹配}
本文研究的问题主要是一个静态PPI网络与一个动态PPI网络的匹配，两个动态PPI网络之间的匹配留作未来的研究工作。

有一个静态PPI网络$G_1=(V_1,E_1)$和一个动态PPI网络$G_2=(V_2,E_2,L,R)$，$|V_1|\leq |V_2|$定义动态PPI匹配$f:V_1\rightarrow V_2$为点集$V1$到点集$V2$的一个单射。

在源网络$G_1$中，如果边$(u,v)$在时刻$i$满足$Act_i(f(u),f(v))=1$，则称边$(u,v)$在时刻$i$是被保留（匹配）的。

定义$f_i(E_1)=|\{(u,v):(u,v)\in E_1, \text{且} (u,v)\text{在$i$时刻是被保留的}\}|$为源网络边集$E_1$在$i$时刻被保留的边的集合。

在动态PPI网络的环境下，所有的匹配衡量标准都需要重新定义，我们称这些衡量标准为动态匹配衡量标准(dynamic alignment quality measure)。分别有
\begin{equation}\label{myworkecdefine}
    EC(f)=\underset{i}{max}\frac{\left | f_i(E_1) \right |}{\left | E_1 \right |}
\end{equation}
\begin{equation}\label{myworkicsdefine}
    ICS(f)=\underset{i}{max}\frac{\left | f_i(E_1) \right |}{\left |Act_i(E_2(G_2[f(V_1)]))\right |}
\end{equation}
\begin{equation}\label{myworks3define}
S^{3}(f)=\underset{i}{max}\frac{\left | f_i(E_1) \right |}{\left | E_1 \right |+\left |Act_i(E_2(G_2[f(V_1)])) \right |-\left | f_i(E_1) \right |}
\end{equation}
\begin{equation}\label{myworktwecdefine}
    TWEC(f)=\frac{EC(f)+ICS(f)}{2}
\end{equation}
可以看到，在动态PPI网络的环境下，所有的衡量标准，都得到了动态化的定义，其本质，就是在匹配$f$下，将动态PPI网络看成若干个静态网络后，将源网络与这些静态网络逐个进行匹配结果衡量，最终选取值最大的结果。

有了动态匹配衡量标准的定义，对于本文研究的问题，便是找到一个匹配$f$使得动态匹配衡量标准最大化，即
\begin{equation}\label{myworktwobjdefine}
    objf=\underset{f}{argmax}Q(f)
\end{equation}
其中的$Q$可以是上述衡量标准的任意一项。针对$objf$，是否可以用已有的静态网络匹配算法来寻找呢？

%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\section{静态匹配算法的缺陷}
根据新的动态PPI网络匹配定义以及衡量匹配的标准，是否可以将已有的静态网络匹配算法应用到动态PPI网络匹配这个问题上呢？答案是肯定的，但是缺点就是时间或者匹配效果的下降。

第一种方案是，单纯忽略$L$和$R$的信息，将$G_2(V_2,E_2,L,R)$转化成对应的静态PPI网络$G_2(V_2,E_2)$，然后利用静态PPI网络匹配算法去算得匹配$f$，当做最后的结果$objf$。但是这样做的问题在于，直接把动态PPI网络的一条边当做静态网络边，意味着这条边在所有时刻都是活跃的，但是实际上这条边只在某些时刻才是处于活跃状态的，因此既有的匹配算法无论在相似度的估计上，还是匹配生成上，都会被这条看似永久活跃，其实只在某些时候活跃的边所“迷惑”，产生不精准的相似度估计或者匹配方案。

第二种方案，便是将动态PPI网络$G_2$拆分成若干张静态PPI网络，然后逐个进行匹配，从中选取拥有最好匹配效果的匹配方案。这种方法的好处在于，匹配算法确实是跑在了真实的网络上，但是缺点在于时间，假设动态PPI网络的时间跨度非常大，那么这种方法会让匹配算法非常耗时（从本来的只要匹配一次变成匹配$N$次），这对于一些已经比较耗时的匹配算法来说，无疑是不可接受的。

因此，我们希望得到一个不但时间消耗不大，且依旧能够得到较优匹配效果的算法。为此，本文提出了SGOPT（SeGment tree OPTimization）算法，不仅能够在既有静态匹配算法的基础上提高匹配效果，时间上也不会像逐个匹配一般地耗时，可以说是一种折中的算法，最关键的是，它是基于动态PPI网络所提出的算法，不同于已有的静态匹配算法，是对动态PPI网络这个新环境下的新问题的一种创新性的尝试。
%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\section{SGOPT算法}
这一部分主要介绍SGOPT算法，也是本文主要工作所在。可以看到，在所有动态匹配衡量标准的定义中，分子都是$|f_i(E_1)|$，而这个分子的意义，就是在$i$时刻，源网络$G_1$在通过匹配$f$的情况下，$E_1$中仍然被保留（匹配）的边的集合。一个直观的想法，就是不断调整匹配$f$，使得

\begin{equation}\label{myworkmaxfidefine}    
\underset{i}{max}\{ |f_i(E_1)|\}
\end{equation}

最大化。而要计算公式\ref{myworkmaxfidefine}的值，需要考查每一时刻$i$下，$E_1$中被保留的边数，假设时间跨度为$T$，则需要$\mathcal{O}(|E_1|*T)$的时间才能完成。SGOPT算法做的第一步，就是将这个时间从$\mathcal{O}(|E_1|*T)$变成了$\mathcal{O}(|E_1|*log(T))$，也就是说，对于$E_1$中的一条边，计算它在所有时刻内是否被保留，从原本的时间复杂度$\mathcal{O}(T)$，变成了$\mathcal{O}(log(T))$。

SGOPT算法的第二步，则是在第一步时间优化的基础上，通过一种局部调整的策略，逐步匹配$f$，使得公式\ref{myworkmaxfidefine}最大化。

SGOPT算法的第一步，从时间上优化了计算匹配衡量标准的计算耗时，第二步则是从第一步的基础上，使得对动态PPI网络的匹配，可以从逐个匹配的劣势下，变为只对一个网络进行匹配。

%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\subsection{从$\mathcal{O}(T)$到$\mathcal{O}(log(T))$的转化}
先考虑这样一个问题，假设有一个整数序列，长度为$T$，序列为

\begin{equation}\label{myworkseqdefine}    
[a_1,a_2,a_3,.....,a_T]
\end{equation}

其中$a_i$为序列中第$i$个整数。现在有三种操作。

第一种，把第$l$个到第$r$个（$l\leq r$）的所有整数都加上一个共同的数字$d$，简称$ADD(l,r,d)$。

第二种，把第$l$个到第$r$个（$l\leq r$）的所有整数都减去一个共同的数字$d$，简称$SUB(l,r,d)$。

第二种，求出第$l$个到第$r$个（$l\leq r$）的所有整数中最大的那个数，简称$MAX(l,r)$。

那么如何快速地完成这些操作呢？答案是用线段树（segment tree）这种数据结构\cite{de2000computational}。线段树是一种非常适合维护区间上操作的数据结构，对于一个长度不超过$T$的区间，其本质是一颗高度不超过$\mathcal{O}(log(T))$满二叉树，线段树的空间复杂度为$\mathcal{O}(T)$，而对于上述的三种操作中的任意一种操作，线段树都能够在不超过树高$\mathcal{O}(log(T))$的时间复杂度内完成。

那么这个问题对于本文研究的问题有什么作用呢？答案是可以将计算公式\ref{myworkmaxfidefine}的过程转化成该问题，然后用线段树在$\mathcal{O}(log(T))$时间内解决。

考虑本文研究问题的一个部分匹配$fp$，不同于$f$的是，$G_1$中的点$v$在部分匹配$fp$下可能并没有对应的$G_2$中的匹配点，用$fp(v)=undefined$来表示。同时用$fp^{-1}(v)=undefined$来表示$G_2$中的点$v$并没有被$G_1$中的任何一个点所匹配。

假设在$fp$这个匹配下，我们已经知道了所有的$|fp_i(E_1)|$的值($fp_i(E_1)$即为在匹配fp的情况下，在$i$时刻时$E_1$中被保留的边的集合。)，这样的值共有$T$个，构成了一个整数序列，定义为

\begin{equation}\label{myworkfseqdefine}    
SEQ(fp)=[|fp_1(E_1)|,|fp_2(E_1)|,.....,|fp_T(E_1)|]
\end{equation}

现在，我们需要往$fp$匹配中添加一对新的匹配$(u,v)(u\in V_1,v\in V_2,fp(u)=undefined,fp^{-1}(v)=undefined)$。且令新的匹配为$fn=fp\bigcup (u,v)$。定义

\begin{equation}\label{myworkfadddefine}    
SEQ(fn)=ADD\_MATCH(SEQ(fp),(u,v))
\end{equation}

来表示这样的一种加匹配$(u,v)$的操作，在$ADD\_MATCH$操作后，$SEQ(fp)$变成了$SEQ(fn)$。而$ADD\_MATCH$操作，就是将$fp$匹配下各个时刻的$E_1$保留的边数，变成了$fn$匹配下各个时刻的$E_1$保留的边数。

在添加了匹配$(u,v)$后，考查满足$x\in N(u),y\in N(v),fp(x)=y$的任意点对$(x,y)$。由定义可知，在$E_1$中，边$(u,x)$通过匹配$fn$被映射到了$E_2$中的$(v,y)$，而边$(v,y)$在$[L(v,y),R(v,y)]$这个时间区间内是处于活跃状态的，所以对于任意时刻$i\in [L(v,y),R(v,y)]$，$fn_i(E_1)$因为$(u,v)$匹配的加入，而在$fp_i(E_1)$的基础上，多了$(u,x)$这一条边。也就是说，$SEQ(fp)$这个序列在$[L(v,y),R(v,y)]$这个区间内的所有数值都加了1，这不就是对$SEQ(fp)$进行了ADD(L(v,y),R(v,y),1)操作么？

如果用一颗长度为$T$的线段树来维护$SEQ(fp)$，那么每次的$ADD\_MATCH$操作，都可以通过对该线段树进行若干次（由符合条件的u和v的邻居点对个数决定）$ADD$操作来实现从$SEQ(fp)$到$SEQ(fn)$的转化，因此，其时间复杂度就是$\mathcal{O}(log(T))$。而通过不断加匹配，从部分匹配变成单射的时候（即$G_1$中每个点都得到了匹配），这颗线段树所维护的，正是$SEQ(f)$，而$SEQ(f)$中的最大值，正是公式\ref{myworkmaxfidefine}所要求的值，可以通过对该线段树进行$MAX(1,T)$操作来得到。这样，我们就完成了从$\mathcal{O}(T)$到$\mathcal{O}(log(T))$的转化。

%@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
\subsection{局部调整策略}
在有了线段树这一利器后，我们已经做到了可以对任意部分匹配$fp$，随时维护$SEQ(fp)$，根据$ADD\_MATCH$操作，我们可以从一个空的匹配集合和一颗序列长度为$T$且数值全为0的线段树开始，不断加入新的匹配$(u,v)$，在$\mathcal{O}(log(T))$的时间内更新序列，直到再没有匹配能够加入为止，最终产生的结果就是全局匹配$f$。

因此，利用这个框架，SGOPT算法可以结合任意已有的静态PPI网络匹配算法，将它们的匹配$f$结果作为输入，可以在$\mathcal{O}(|E_1|*log(T))$时间内算出$SEQ(f)$，比之前$\mathcal{O}(|E_1|*T)$的方式快了很多。

而且，在这个框架下，我们不但可以加入匹配，也可以删除匹配，同样可以在$\mathcal{O}(log(T))$时间内维护$SEQ(fp)$，比原本$\mathcal{O}(T)$的时间快了许多。因此，在这个优化框架下，本文提出了一种能够在动态PPI网络环境下的局部调整策略，使得得到的匹配在公式\ref{myworkmaxfidefine}下最大化。

类似于$ADD\_MATCH$，定义$DEL\_MATCH(SEQ(fn),(u,v))$操作表示将匹配$(u,v),fp(u)=v$从匹配$fn$中删去，而得到的新的匹配为$fp=fn-{(u,v)}$。对于删除匹配$(u,v)$，考查满足$x\in N(u),y\in N(v),fn(x)=y$的任意点对$(x,y)$，进行$SUB(L(v,y),R(v,y),1)$操作，同样可以在$\mathcal{O}(log(T))$的时间复杂度内完成。

于是，对于一个匹配$fp$，无论是添加一对匹配$(u,v)$，还是删除一对匹配$(u,v)$，都可以在$\mathcal{O}(log(T))$内做到。

局部调整策略的伪代码可以见算法\ref{alg:1}。算法的总体思想是通过随机删除已有匹配的一部分，并且加入一部分别的匹配来调整当前匹配。

$\alpha$和$\beta$都是参数，分别表示迭代次数上限以及匹配删除比例。

第1行到第3行是初始化过程，对于任意匹配$f$，算法将该匹配$f$作为需要调整的初始匹配，用线段树来维护$SEQ$序列。$ADD\_MATCH(SEQ,f)$是一系列$ADD\_MATCH(SEQ,(u,v)),(u,v)\in f$操作的集合（下同）。

第5行到第20行是整个迭代的循环，迭代的次数有$\alpha$参数决定，整个循环是不断调整既有匹配集合$fp$的过程。

第6行到第11行，算法从$fp$中随机挑出若干个匹配，挑出的数目由参数$\beta$决定，并且把这些匹配从$fp$中用操作$DEL\_MATCH(SEQ,f\_delete)$删去。

第12行到第12行，算法构造了一个二分图$bg$，点集分别有$G_1$和$G_2$中未被匹配的点构成，而任意点对$(u,v)$直接间的权重，由函数$NS(fp,u,v)$决定。

\begin{equation}\label{myworknsdefine}
    NS(f,u,v)=|\{(x,y):x\in N(u),y\in N(v),f(x)=y\}|
\end{equation}
$NS(f,u,v)$的值本质上，就是在匹配$f$的情况下，如果加入匹配$(u,v)$，能够对$E_1$中保留的边数增加的一个数值的估计，直观上可以认为，$NS(f,u,v)$越大，匹配$(u,v)$的效果越好。

第13行到第19行，得到二分图$bg$的最大权重匹配，将对应的匹配加入得到新的$fp$，最后比较新的$fp$在调整前后的好坏，如果好于调整前的，则说明这轮迭代找到了一个更优的匹配，否则，进行下一轮的迭代。

值得说明的是，这个二分图的最大权重匹配，不包括权值为0的边（对既有匹配没有任何贡献效益），所以在这个调整过程中，会存在某些点没有得到匹配，所以这些点在下一轮迭代中，和会那些被删掉匹配的点放在一起，重新构建一个新的二分图。这就导致了该算法可能会出现的“换入换出”(swap-in,swap-out)效果。每一次迭代，算法会“换出”一部分匹配，同时，“换入”一部分之前被删掉的匹配。本文认为，这样的局部调整策略具有较好的效果。

此算法的时间复杂度为$\mathcal{O}(\alpha\beta log(T))$，和两个参数息息相关。过小的参数可能会导致匹配效果糟糕，过大的参数，则会导致算法非常耗时，因此，需要在两个参数之间作出权衡。

\begin{small}
\begin{algorithm}[!htb]
{
\caption{局部调整算法}
\label{alg:1}
    \begin{algorithmic}[1]
    \Require
    $G_1(V_1,E_1)$：源网络
    
    $G_2(V_2,E_2,L,R)$：目标网络
    
    $f$：当前匹配
    
    $\alpha$：参数$\alpha>0$
    
    $\beta$：参数$0<\beta<1$
    
    \Ensure
    $fp$: 新的匹配
    
    \State $fp \gets f$
    \State $SEQ \gets [0,0,...,0]$
    \State $SEQ \gets ADD\_MATCH(SEQ,f)$
    \State $iteration\_count \gets 0$
    \While{$iteration\_count<\alpha$}
        \State $iteration\_count\gets iteration\_count+1$
        \State $oldSEQ\gets oldSEQ$
        \State $oldfp\gets fp$
        \State $f\_delete\gets$从$fp$中随机挑选的$\beta*|V_1|$个匹配
        \State $SEQ\gets DEL\_MATCH(SEQ,f\_delete)$
        \State $fp \gets fp-f\_delete$
        \State $bg\gets WeightedBipartiteGraph(\{u:fp(u)=undefined\},\{v:fp^{-1}(v)=undefined\},NS(fp,u,v))$
        \State $M\gets MaximumWeightedBipartiteGraphMaching(bg)$
        \State $fp\gets fp\bigcup M$
        \State $SEQ\gets ADD\_MATCH(SEQ,M)$
        \If{$MAX(SEQ)<MAX(oldSEQ)$}
            \State $SEQ\gets oldSEQ$
            \State $fp\gets oldfp$
        \EndIf
    \EndWhile
    \end{algorithmic}    
}
\end{algorithm}
\end{small}


